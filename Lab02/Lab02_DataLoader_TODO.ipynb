{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icGbEQnw0kyd"
   },
   "source": [
    "# Laboratorium 2: DataLoadery i prosta sieć CNN (MedMNIST – PneumoniaMNIST)\n",
    "\n",
    "**Cel:** nauczyć się przygotowywania **własnego Datasetu** w PyTorch oraz wykorzystać go do **szybkiego treningu prostej sieci CNN** na małym, medycznym zbiorze danych.\n",
    "\n",
    "\n",
    "> **Dataset:** użyjemy **PneumoniaMNIST** z kolekcji **MedMNIST** – to mały, 2-klasowy zbiór obrazów RTG płuc (zapalenie płuc vs brak). Dataset zostanie **automatycznie pobrany** w notebooku. Użyty zostanie też dataset **OrganMNIST3D** do klasyfikacji organów na podstawie danych trójwymiarowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMZq77GE0kyf"
   },
   "source": [
    "## 0) Instalacja i importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1759913964660,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "dgyGDQ560kyf",
    "outputId": "0de85502-e104-474d-93be-371ed8da0709"
   },
   "outputs": [],
   "source": [
    "# !pip -q install medmnist torchmetrics tqdm --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import os, sys, time, json, math, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryConfusionMatrix\n",
    "\n",
    "import medmnist\n",
    "from medmnist import PneumoniaMNIST\n",
    "from medmnist import INFO\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dfV3yZv0kyh"
   },
   "source": [
    "## 1) Pobranie i eksploracja danych (MedMNIST – PneumoniaMNIST)\n",
    "\n",
    "Skrypt automatycznie pobiera zbiór **PneumoniaMNIST**. Poniższy kod sprawdza rozmiar danych i etykiety.\n",
    "Wyświetlone zostaje również 6 pierwszych próbek z tego zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1759913965093,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "7V6VzjzA0kyh",
    "outputId": "63849ad9-7c30-4402-d239-aa0e5e70bea0"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./data/medmnist\"\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "info = INFO['pneumoniamnist']\n",
    "print(\"Opis:\", info['description'])\n",
    "print(\"Liczba klas:\", len(info['label']), \"; klasy:\", info['label'])\n",
    "\n",
    "# Print image shape using the first image in the train set\n",
    "sample_img, _ = PneumoniaMNIST(split='train', download=True, root=DATA_ROOT, as_rgb=False)[0]\n",
    "print(\"Rozmiar obrazów:\", np.array(sample_img).shape)\n",
    "\n",
    "train_set_raw = PneumoniaMNIST(split='train', download=True, root=DATA_ROOT, as_rgb=False)\n",
    "val_set_raw   = PneumoniaMNIST(split='val',   download=True, root=DATA_ROOT, as_rgb=False)\n",
    "test_set_raw  = PneumoniaMNIST(split='test',  download=True, root=DATA_ROOT, as_rgb=False)\n",
    "\n",
    "print(\"Rozmiary:\", len(train_set_raw), len(val_set_raw), len(test_set_raw))\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(10,2))\n",
    "for i in range(6):\n",
    "    img, label = train_set_raw[i]\n",
    "    img_np = np.array(img)\n",
    "    axes[i].imshow(img_np, cmap='gray')\n",
    "    axes[i].set_title(f\"y={int(label.squeeze().item())}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTyDCKnT0kyi"
   },
   "source": [
    "## Zadanie 1 – Własny `Dataset` i `DataLoader`\n",
    "\n",
    "W pierwszym kroku chcemy przygotować własny Datasoader dla zbioru PneumoniaMNIST. Dla popularnych zbiorów danych zazwyczaj nie ma konieczności pisania własnego Datasetu, ale dobrze jest wiedzieć jak powinien on działać.\n",
    "Dataset jest klasą dziedziczącą po klasie `Dataset` z `torch.utils.data`, która pozwala na wczytywanie danych. Musi ona zawierać przynajmniej 3 metody: `__init__` - stworzenie i inicjalizacja obiektów klasy, `__len__` - sprawdzenie liczby dostępnych próbek, `__getitem__` - pobranie próbki o zadanym indeksie. Zazwyczaj Dataset odpowiedzialny jest również za transformacje i augmentację danych, ale tym będziemy zajmować się później.\n",
    "W naszym przypadku zbiór danych jest bardzo mały, więc możemy cały trzymać w pamięci, ale zazwyczaj dane są przechowywane na dysku i odczytywane dopiero wtedy, kiedy musimy je przetworzyć (czyli stosujemy lazy loading).\n",
    "\n",
    "1. Zaimplementuj klasę `PneumoniaCustomDataset`, która dziedziczy po klasie `Dataset`.\n",
    "2. Zaimplementuj metodę `__init__`, której argumentami jest zbiór obrazów oraz zbiór odpowiadających im etykiet. Powinny one zostać zapamiętane jak pola obiektu. Dla etykiet wywołaj dodatkowo metodę `.squeeze()`.\n",
    "3. Zaimplementuj metodę `__len__`, która sprawdza liczbę zapamiętanych podczas inicjalizacji obrazów.\n",
    "4. Zaimplementuj metodę `__getitem__`, której argumentem jest indeks pobieranej próbki. W tym miejscu powinniśmy zapewnić, że zwracane próbki są oczekiwanego typu i rozmiaru.\n",
    "5. Zacznij od pobrania obrazu i etykiety o zadanym indeksie.\n",
    "6. Następnie wykonaj konwersję obrazu do tensora za pomocą `transforms.ToTensor()(x)`.\n",
    "7. Wykonaj konwersję etykiet do tensora za pomocą `torch.tensot`. Docelowym typem danych powinien być `torch.long`.\n",
    "8. Zwróć próbkę danych oraz etykietę.\n",
    "9. Poza klasą stwórz 3 datasety: treningowy, walidacyjny i testowy. Dane oraz etykiety można pobrać z wcześniejszych danych, np. `train_set_raw.imgs` lub `train_set_raw.labels`.\n",
    "10. Wyświetl ile elementów zawiera każdy z nich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1759913965094,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "a3gLLXf20kyi",
    "outputId": "38a6cebe-4c10-48cc-cef7-aa9e6513ea74"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 1\n",
    "\n",
    "class PneumoniaCustomDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"\n",
    "        images: numpy array lub lista obrazów\n",
    "        labels: numpy array lub lista etykiet\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels.squeeze()\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Zwraca liczbę próbek w zbiorze.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Zwraca obraz i etykietę o zadanym indeksie.\"\"\"\n",
    "        x = self.images[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        x = self.transform(x)  # (H,W) -> tensor (1,H,W)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_dataset = PneumoniaCustomDataset(train_set_raw.imgs, train_set_raw.labels)\n",
    "val_dataset   = PneumoniaCustomDataset(val_set_raw.imgs, val_set_raw.labels)\n",
    "test_dataset  = PneumoniaCustomDataset(test_set_raw.imgs, test_set_raw.labels)\n",
    "\n",
    "print(f\"Liczba próbek w zbiorze treningowym: {len(train_dataset)}\")\n",
    "print(f\"Liczba próbek w zbiorze walidacyjnym: {len(val_dataset)}\")\n",
    "print(f\"Liczba próbek w zbiorze testowym: {len(test_dataset)}\")\n",
    "\n",
    "x, y = train_dataset[0]\n",
    "print(f\"Typ x: {type(x)}, kształt: {x.shape}\")\n",
    "print(f\"Typ y: {type(y)}, wartość: {y}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLEnp49Q0kyj"
   },
   "source": [
    "## Zadanie 2 –  DataLoadery: batching, shuffle, num_workers\n",
    "\n",
    "Z kolei celem DataLoaderu jest wydajne dostarczanie batchy danych do treningu. Nie dostarcza on pojedynczych próbek, lecz cały ich zbiór nazywany batchem. Zajmuje sie również mieszaniem danych, żeby nie były przekazywane w tej samej kolejności, pozwala na rónoległe wczytywanie danych i zwraca iterator, dzięki czemu łatwo jest przejść po wszystkich próbkach danych. Do stworzenia DataLoadera wykorzystuje się gotową klasę `DataLoader`. Nie trzeba jej implementować samodzielnie.\n",
    "\n",
    "1. Zacznij od zdefiniowania rozmiaru batchów `BATCH_SIZE` i liczby workerów `NUM_WORKERS`.\n",
    "2. Stwórz 3 DataLoadery - odpowiednio treningowy, walidacyjny i testowy. Pierwszym argumentem powinien być obiekt Dataset wykorzystywany do wczytania danych. Oprócz tego przekazujemy `batch_size`, `shuffle` (wartość boolean), `num_workers` i `pin_memory` (wartość boolean). Mieszania danych (shuffle) używa się tylko dla danych treningowych. `pin_memory` pozwala na szybsze kopiowanie danych w przypadku uczenia na GPU i wtedy warto ustawić `True`.\n",
    "3. Stwórz pętlę przechodzącą po danych treningowych. Pamiętej, że DataLoader zwrócił iterator. Sprawdź rozmiar pojenynczego zestawu treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1759913965214,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "FfizqZnS0kyk",
    "outputId": "7b1ca929-9147-4140-c71b-7a17350950e1"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx+1}:\")\n",
    "    print(f\"  - x_batch shape: {x_batch.shape}\")\n",
    "    print(f\"  - y_batch shape: {y_batch.shape}\")\n",
    "    print(f\"  - Typy: x={x_batch.dtype}, y={y_batch.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t93TB2wF0kyl"
   },
   "source": [
    "## Zadanie 3 – Prosta sieć CNN\n",
    "\n",
    "Teraz zaimplementujemy prostą sieć konwolucyjną, której celem będzie klasyfikacja pacjentów na podstawie zdjęć jako zdrowi lub chorzy.\n",
    "1. Zaimplementuj klasę `SimpleCNN`, która dziedziczy po klasie `nn.Module`. Taka klasa musi posiadać przynajmniej dwie metody: `__init__`, gdzie zdefiniowane są warstwy i parametry sieci, oraz `forward`, która określa jak dane przepływają przez sieć.\n",
    "2. Stwórz metodę `__init__`, która będzie zawierać dwie warstwy konwolucyjne `nn.Conv2d`, warstwę MaxPool `nn.MaxPool2d` i dwie warstwy liniowe `nn.Linear`. Wybierz rozmiar warstw konwolucyjnych oraz dobierz padding tak, aby rozmiar wyjściowy był taki sam jak wejściowy. Wybierz również liczbę kanałów wyjściowych z tych warstw.\n",
    "3. Dodaj warstwę pooling, tak, żeby zmniejszyła rozmiar o połowę.\n",
    "4. Stwórz dwie warstwy w pełni połączone. Rozmiar wejścia pierwszej z nich powinien być równy rozmiarowi pomnożonemu przez liczbę kanałów. Dobierz liczbę kanałów na wyjściu. Ostatnia warstwa powinna mieć na wyjściu tylko dwa kanały.\n",
    "5. Zaimplementuj metodę `forward`, której arguemntem jest próbka do przetworzenia. Wejście najpierw wchodzi na pierwszą warstwę konwolucyjną, później idzie do funkcji aktywacji ReLU `F.relu`, a dalej do warstwy poolingowej.\n",
    "Następnie te same operacje wykonujemy dla drugiej warstwy konwolucyjnej. Dalej spłaszczamy dane przed podaniem ich do warstwy w pełni połączonej `torch.flatten` (drugim argumentem powinno być `1`, żeby nie usunąć wymiaru batch). Po pierwszej z tych warstw wykorzystujemy funkcję aktywacji ReLU, a następnie podajnemy na drugą z tych warstw i zwracamy jej wynik.\n",
    "6. Cały schemat wygląda następująco: (1, 28, 28) --> Conv2d --> ReLU--> MaxPool2d(2x2) --> Conv2d --> ReLU --> MaxPool2d(2x2) --> Flatten --> Linear --> ReLU --> Linear --> logits.\n",
    "7. Poza klasą wybierz urządzenie na którym sieć ma być uruchomiona: `device = 'cuda' if torch.cuda.is_available() else 'cpu'`.\n",
    "8. Stwórz instancję sieci i załaduj ją do wybranego urządzenia za pomocą metody `.to`\n",
    "9. Zdefiniuj funkcję straty jako `nn.CrossEntropyLoss()` i optymalizator jako `torch.optim.Adam`. Pierwszym argumentem optymalizatora są parametry sieci `.parameters()`, a drugim `lr`, czyli learning rate, określający jak szybko parametry modelu mają się zmieniać.\n",
    "10. Wypisz warstwy modelu za pomocą `print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759913965234,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "gRHcUCqI0kyl",
    "outputId": "f3fc20c5-2bdf-4df2-f3a3-238abb2d80e7"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 3\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = 'cuda'\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGwba8ED0kym"
   },
   "source": [
    "## Zadanie 4 – Trening\n",
    "\n",
    "Teraz konieczne jest przeprowadzenie treningu zdefiniowanego modelu.\n",
    "\n",
    "1. Zaimplementuj funkcję `run_epoch`, której zadaniem będzie wykonanie pojedynczej epoki treningu. Epoka to jedno pełne przejście modelu przez cały zbiór treningowy. Jej argumentami są: model sieci, DataLoader, optymalizator i urządzenie na którym sieć jest uruchomiona. Zakłądamy, że optymalizator jest przekazywany tylko w przypadku treningu, natomiast podczas ewaluacji wynosi `None`.\n",
    "2. Na początku funkcji sprawdź czy optymalizator nie jest `None`, a więc czy sieć powinna być uczona w tym wywołaniu funkcji.\n",
    "3. Jeśli ma być uczona, to ustaw ją w tryb treningu za pomocą metody `.train`. Jako argument podaj wynik wcześniejszego sprawdzenia.\n",
    "4. Zainicjalizuj `lossTotal`, `correctTotal` i `total` jako 0.0.\n",
    "5. Napisz pętlę, która przetwarza wszystkie dane z przekazanego DataLoadera.\n",
    "6. Prześlij dane do urządzenia za pomocą metody `.to`.\n",
    "7. Jeśli sieć ma być trenowana, to wyzeruj gradienty w optymalizatorze metodą `.zero_grad()`.\n",
    "8. Oblicz wyjście sieci dla danego wejścia.\n",
    "9. Olicz stratę dla przetworzonych danych za pomocą wybranej funkcji straty. Pierwszym argumentem jest wyście sieci, a drugim rzeczywiste etykiety.\n",
    "10. Jeśli sieć ma być uczona, to oblicz gradienty funkcji straty względem parametrów sieci i wykonaj krok optymalizatora. W tym celu wywołaj metodę `.backward()` obliczonej straty,a  następnie wywołaj metodę `.step()` optymalizatora.\n",
    "11. Dodaj obliczoną stratę do `lossTotal`.\n",
    "12. Sprawdź predykcje sieci dla przetworzonych danych. W tym celu wykorzystaj metodę `.argmax` względem wymiaru odpowiedzialnego za batch (jest on argumentem metody).\n",
    "13. Sprawdź ile predykcji było poprawnych. Porównaj wynik z poprzedniego punktu z etykietami, a następnie zsumuj wyniki porównania. Następnie skonwertuj wynikowy tensor na liczbę za pomocą metody `.item()` i dodaj wynik do `correctTotal`.\n",
    "14. Zaktualizuj liczbę wszystkich przetworzonych próbek `total`.\n",
    "15. Zwróć 'lossTotal' i 'correctTotal' podzielone przez liczbę przetworzonych próbek.\n",
    "16. Poza definicją funkcji zdefiniuj liczbę epok treningu. W naszym prostym przypadku powinny wystarczyć 2.\n",
    "17. Zaimplementuj pętlę, która wykona się tyle razy ile zdefiniowana liczba epok.\n",
    "18. W każdej iteracji pętli wywołaj zaimplementowaną funkcję dla zbioru treningowego. Następnie wyłącz oblicznie gradientów `with torch.no_grad():` i wewnątrz wywołaj tą samą funkcję dla zbioru walidacyjnego.\n",
    "19. Na koniec pętli, po każdej epoce, wyświetl numer epoki, stratę i dokładność zarówno dla zbioru treningowego, jak i walidacyjnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4530,
     "status": "ok",
     "timestamp": 1759913994179,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "204YUC4V0kym",
    "outputId": "799371fb-93d5-483d-9259-bc65195935fe"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 4\n",
    "\n",
    "def run_epoch(model, dataloader, optimizer, device):\n",
    "    is_training = optimizer is not None\n",
    "    model.train(is_training)\n",
    "\n",
    "    lossTotal = 0.0\n",
    "    correctTotal = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        lossTotal += loss.item() * x.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correctTotal += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return lossTotal / total, correctTotal / total\n",
    "\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch(model, train_loader, optimizer, device)\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, None, device)\n",
    "\n",
    "    print(f\"Epoka {epoch}: \"\n",
    "          f\"Trening - loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
    "          f\"Walidacja - loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE1gDEtQ0kym"
   },
   "source": [
    "## Zadanie 5 – Ewaluacja (accuracy, macierz pomyłek)\n",
    "\n",
    "Kolejnym elementem jest sprawdzenie skuteczności zaprojektowanego rozwiązania dla zbioru testowego.\n",
    "\n",
    "1. Przełącz model w tryb ewaluacji za pomocą metody `.eval()`.\n",
    "2. Zainicjalizuj wartości `correct` i `total` jako 0. Zaincjalizuj również `cm` jako zerową macierz o rozmiarze $2 \\times 2$. W zmiennej `cm` przechowywać będziemy macierz pomyłek. Jest to tabela, w której porównuje się rzeczywiste etykiety z predykcjami modelu.\n",
    "3. Wyłącz obliczanie gradientów w bloku kodu za pomocą `with torch.no_grad():`. Wewnątrz tego bloku wykonaj przejście po zbiorze testowym. Przedykcje modelu (po `.argmax`) prześlij na CPU za pomocą metody `.cpu()`. Upewnij się, że etykiety również są na CPU wywołując `.cpu()`.\n",
    "4. Oblicz `correct` i `total` podobnie jak w poprzednim zadaniu.\n",
    "5. Oprócz tego musimy zaktualizować macierz pomyłek. W tym celu do aktualnej macierzy dodajemy nową macierz, utworzoną na podstawie predykcji i etykiet. Macierz pomyłek tworzymy za pomocą funkcji `confusion_matrix`. Pierwszym argumentem są rzeczywiste etykiety, drugim są obliczone predykcje, a trzecim jest wektor etykiet `labels` (w naszym przypadku `[0, 1]`).\n",
    "6. Na zewnątrz pętli oblicz i wyświetl dokładność dla zbioru testowego.\n",
    "7. Na koniec wyświetl macierz pomyłek. Stwórz wizualizację za pomocą funkcji `ConfusionMatrixDisplay`. Jako argument `confusion_matrix` podaj wyznaczoną macierz pomyłek, a jako argument `display_labels` podaj wektor nazw dla klas `['normal','pneumonia']`. Wyświetl wynik za pomocą metody `.plot()`, a następnie `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1759913994448,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "JjMuCwa30kym",
    "outputId": "15d35d03-6286-43e7-d510-de0156ce78c4"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 5\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "cm = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        cm += confusion_matrix(\n",
    "            y.cpu(), preds.cpu(), labels=[0, 1]\n",
    "        )\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Dokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'pneumonia'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Macierz pomyłek – zbiór testowy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zM0dxcx0kym"
   },
   "source": [
    "## Zadanie 6 – Zapis modelu\n",
    "\n",
    "Ostatnim etapem jest zapisanie słownika z parametrami modelu.\n",
    "1. Zdefiniuj ścieżkę do pliku.\n",
    "2. Pobierz słownik z parametrami za pomocą metody `.state_dict()`.\n",
    "3. Zapisz słownik za pomocą funkcji `torch.save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1759913968324,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "r5qLDeWp0kym",
    "outputId": "db6071af-1005-46b1-b001-8823f3f3e171"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 6\n",
    "\n",
    "save_path = \"./simplecnn_pneumoniamnist.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Model zapisano pod ścieżką: {os.path.abspath(save_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QskjZ3x00kyn"
   },
   "source": [
    "## Zadanie 7 – Wykonaj podobną klasyfikację dla zbioru danych OrganMNIST3D\n",
    "\n",
    "Poniższy kod automatycznie pobiera dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1759913969177,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "IQU0rj120kyn",
    "outputId": "b2eaf107-1661-4ef1-fb3d-0f9d5c9580a0"
   },
   "outputs": [],
   "source": [
    "from medmnist import OrganMNIST3D, INFO\n",
    "\n",
    "DATA_ROOT = \"./data/medmnist\"\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "info = INFO['organmnist3d']\n",
    "print(\"Opis:\", info['description'])\n",
    "num_classes = len(info['label'])\n",
    "print(\"Liczba klas:\", num_classes, \"; klasy:\", info['label'])\n",
    "\n",
    "# Print image shape using the first image in the train set\n",
    "sample_img, _ = OrganMNIST3D(split='train', download=True, root=DATA_ROOT, as_rgb=False)[0]\n",
    "print(\"Rozmiar obrazów:\", np.array(sample_img).shape)\n",
    "\n",
    "to_float32 = lambda x: torch.tensor(x, dtype=torch.float32) / 255.0\n",
    "\n",
    "train_raw = OrganMNIST3D(split='train', download=True, root=DATA_ROOT, as_rgb=False, transform=to_float32)\n",
    "val_raw   = OrganMNIST3D(split='val',   download=True, root=DATA_ROOT, as_rgb=False, transform=to_float32)\n",
    "test_raw  = OrganMNIST3D(split='test',  download=True, root=DATA_ROOT, as_rgb=False, transform=to_float32)\n",
    "\n",
    "print(\"Rozmiary:\", len(train_raw), len(val_raw), len(test_raw))\n",
    "\n",
    "# Szybki podgląd wolumenu 3D (3 losowe przekroje axial)\n",
    "sample_vol, sample_y = train_raw[0]   # numpy array shape (1,28,28,28), label np.int\n",
    "z_slices = sorted(random.sample(range(sample_vol.shape[-1]), 3))\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9,3))\n",
    "for ax, z in zip(axes, z_slices):\n",
    "    ax.imshow(sample_vol[0, :, :, z], cmap='gray')\n",
    "    ax.set_title(f\"z={z}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout(); plt.show()\n",
    "print(\"Przykładowa etykieta:\", int(sample_y.squeeze().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcVqmImL0kyn"
   },
   "source": [
    "## Zadanie 8 – Stwórz DataLoader dla zbioru danych OrganMNIST3D\n",
    "\n",
    "Nie musisz pisać własnego Datasetu. Skorzystaj ze zwracanych przez funkcję `OrganMNIST3D`. Zwróć jaki teraz jest kształt danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1759913969208,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "WPhl8ZvT0kyn",
    "outputId": "88568fb5-0b7c-418f-cbc6-f52aa899ea61"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 8\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "\n",
    "train_loader_3d = DataLoader(\n",
    "    train_raw,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "val_loader_3d = DataLoader(\n",
    "    val_raw,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader_3d = DataLoader(\n",
    "    test_raw,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "# Sprawdzenie kształtu danych z loadera\n",
    "for x_batch, y_batch in train_loader_3d:\n",
    "    print(f\"x_batch shape: {x_batch.shape}\")\n",
    "    print(f\"y_batch shape: {y_batch.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEd8G7nk0kyn"
   },
   "source": [
    "## Zadanie 9 – Stwórz prostą sieć dla zbioru danych OrganMNIST3D\n",
    "\n",
    "Zamiast `nn.Conv2d` wykorzystaj `nn.Conv3d`, a zamiast `nn.MaxPool2d` użyj `nn.MaxPool3d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1759914399716,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "Z0sx_SXg0kyo",
    "outputId": "c73d09d9-7942-486a-d3fd-7a36711c9002"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 9\n",
    "\n",
    "\n",
    "class SimpleCNN3D(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super(SimpleCNN3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        self.conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7 * 7, 128)  # 28->14->7 po pooling\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_3d = SimpleCNN3D(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_3d.parameters(), lr=0.001)\n",
    "\n",
    "print(model_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n3eYbTa0kyo"
   },
   "source": [
    "## Zadanie 10 – Wykonaj trening sieci dla zbioru danych OrganMNIST3D\n",
    "\n",
    "W tym przypadku może być potrzebne 20 epok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17594,
     "status": "ok",
     "timestamp": 1759914421208,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "pFPz9ZKz0kyo",
    "outputId": "a1efd8cd-f03d-48c5-817d-421b86396dc6"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 10\n",
    "\n",
    "def run_epoch_3d(model, dataloader, optimizer, device):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    lossTotal = 0.0\n",
    "    correctTotal = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).long().view(-1)  # <-- zamiast squeeze()\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        lossTotal += loss.item() * x.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correctTotal += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return lossTotal / total, correctTotal / total\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch_3d(model_3d, train_loader_3d, optimizer, device)\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = run_epoch_3d(model_3d, val_loader_3d, None, device)\n",
    "\n",
    "    print(f\"Epoka {epoch}: \"\n",
    "          f\"Trening - loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
    "          f\"Walidacja - loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40alFwNs0kyo"
   },
   "source": [
    "## Zadanie 11 – Sprawdź dokładność i macierz pomyłek dla zbioru danych OrganMNIST3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1759914539330,
     "user": {
      "displayName": "JAN ROSA",
      "userId": "09972594920799623787"
     },
     "user_tz": -120
    },
    "id": "TYJc7Tmi0kyo",
    "outputId": "1e74a7c0-5bdf-4850-fe62-9d867c999caf"
   },
   "outputs": [],
   "source": [
    "# --- Zadanie 11\n",
    "\n",
    "model_3d.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_3d:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).long().view(-1)\n",
    "\n",
    "        outputs = model_3d(x)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        cm += confusion_matrix(y.cpu(), preds.cpu(), labels=list(range(num_classes)))\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Dokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "labels = list(info['label'].values())\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Macierz pomyłek – zbiór testowy 3D\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
